{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c03e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"Hub version:\", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602df745",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' In `data` we created two different folders - one for each class label\n",
    "'''\n",
    "data_dir_train = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066f10b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_data_augmentation = True\n",
    "do_fine_tuning = False\n",
    "epochs = 5\n",
    "BATCH_SIZE = 32\n",
    "validation_split = 0.2\n",
    "\n",
    "# select a model from the list below (efficientnet_b0, efficientnet_b1, ...)\n",
    "model_name = \"mobilenet_v3_large_100_224\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdcc72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_handle_map = {\n",
    "  \"efficientnet_b0\": \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\",\n",
    "  \"efficientnet_b1\": \"https://tfhub.dev/tensorflow/efficientnet/b1/feature-vector/1\",\n",
    "  \"efficientnet_b2\": \"https://tfhub.dev/tensorflow/efficientnet/b2/feature-vector/1\",\n",
    "  \"efficientnet_b3\": \"https://tfhub.dev/tensorflow/efficientnet/b3/feature-vector/1\",\n",
    "  \"efficientnet_b4\": \"https://tfhub.dev/tensorflow/efficientnet/b4/feature-vector/1\",\n",
    "  \"efficientnet_b5\": \"https://tfhub.dev/tensorflow/efficientnet/b5/feature-vector/1\",\n",
    "  \"efficientnet_b6\": \"https://tfhub.dev/tensorflow/efficientnet/b6/feature-vector/1\",\n",
    "  \"efficientnet_b7\": \"https://tfhub.dev/tensorflow/efficientnet/b7/feature-vector/1\",\n",
    "  \"bit_s-r50x1\": \"https://tfhub.dev/google/bit/s-r50x1/1\",\n",
    "  \"inception_v3\": \"https://tfhub.dev/google/imagenet/inception_v3/feature-vector/4\",\n",
    "  \"inception_resnet_v2\": \"https://tfhub.dev/google/imagenet/inception_resnet_v2/feature-vector/4\",\n",
    "  \"resnet_v1_50\": \"https://tfhub.dev/google/imagenet/resnet_v1_50/feature-vector/4\",\n",
    "  \"resnet_v1_101\": \"https://tfhub.dev/google/imagenet/resnet_v1_101/feature-vector/4\",\n",
    "  \"resnet_v1_152\": \"https://tfhub.dev/google/imagenet/resnet_v1_152/feature-vector/4\",\n",
    "  \"resnet_v2_50\": \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature-vector/4\",\n",
    "  \"resnet_v2_101\": \"https://tfhub.dev/google/imagenet/resnet_v2_101/feature-vector/4\",\n",
    "  \"resnet_v2_152\": \"https://tfhub.dev/google/imagenet/resnet_v2_152/feature-vector/4\",\n",
    "  \"nasnet_large\": \"https://tfhub.dev/google/imagenet/nasnet_large/feature_vector/4\",\n",
    "  \"nasnet_mobile\": \"https://tfhub.dev/google/imagenet/nasnet_mobile/feature_vector/4\",\n",
    "  \"pnasnet_large\": \"https://tfhub.dev/google/imagenet/pnasnet_large/feature_vector/4\",\n",
    "  \"mobilenet_v2_100_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\",\n",
    "  \"mobilenet_v2_130_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/feature_vector/4\",\n",
    "  \"mobilenet_v2_140_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/feature_vector/4\",\n",
    "  \"mobilenet_v3_small_100_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_small_100_224/feature_vector/5\",\n",
    "  \"mobilenet_v3_small_075_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_small_075_224/feature_vector/5\",\n",
    "  \"mobilenet_v3_large_100_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/feature_vector/5\",\n",
    "  \"mobilenet_v3_large_075_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_large_075_224/feature_vector/5\",\n",
    "}\n",
    "\n",
    "model_image_size_map = {\n",
    "  \"efficientnet_b0\": 224,\n",
    "  \"efficientnet_b1\": 240,\n",
    "  \"efficientnet_b2\": 260,\n",
    "  \"efficientnet_b3\": 300,\n",
    "  \"efficientnet_b4\": 380,\n",
    "  \"efficientnet_b5\": 456,\n",
    "  \"efficientnet_b6\": 528,\n",
    "  \"efficientnet_b7\": 600,\n",
    "  \"inception_v3\": 299,\n",
    "  \"inception_resnet_v2\": 299,\n",
    "  \"nasnet_large\": 331,\n",
    "  \"pnasnet_large\": 331,\n",
    "}\n",
    "\n",
    "model_handle = model_handle_map.get(model_name)\n",
    "pixels = model_image_size_map.get(model_name, 224)\n",
    "IMAGE_SIZE = (pixels, pixels)\n",
    "\n",
    "print(f\"Selected model: {model_name} : {model_handle}\")\n",
    "print(f\"Input size {IMAGE_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbc7a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_kwargs = dict(rescale=1./255, validation_split=validation_split)\n",
    "dataflow_kwargs = dict(target_size=IMAGE_SIZE, \n",
    "                       batch_size=BATCH_SIZE,\n",
    "                       interpolation=\"bilinear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8cc3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    **datagen_kwargs)\n",
    "\n",
    "print(\"number of validation images\")\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    data_dir_train, \n",
    "    subset=\"validation\", \n",
    "    shuffle=False,\n",
    "    **dataflow_kwargs)\n",
    "\n",
    "if do_data_augmentation:\n",
    "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "      rotation_range=40,\n",
    "      horizontal_flip=True,\n",
    "      vertical_flip=True,\n",
    "      width_shift_range=0.2, \n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2, \n",
    "      zoom_range=0.2,\n",
    "      **datagen_kwargs)\n",
    "else:\n",
    "    train_datagen = valid_datagen\n",
    "    \n",
    "print(\"number of training images\")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir_train, \n",
    "    subset=\"training\", \n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    **dataflow_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a17643",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"training class 1 %:\", train_generator.labels.sum()/len(train_generator.labels))\n",
    "print(\"validation class 1 %:\", valid_generator.labels.sum()/len(valid_generator.labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8fc53e",
   "metadata": {},
   "source": [
    "###Â Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c286aa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building model with\", model_handle)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n",
    "    hub.KerasLayer(model_handle, trainable=do_fine_tuning),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(train_generator.num_classes,\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    tf.keras.layers.Softmax()\n",
    "])\n",
    "\n",
    "model.build((None,)+IMAGE_SIZE+(3,))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdae895",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0ec54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(lr=0.005, momentum=0.9), \n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8d354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
    "validation_steps = valid_generator.samples // valid_generator.batch_size\n",
    "hist = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs, \n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=validation_steps).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3adad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss (training and validation)\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,2])\n",
    "plt.plot(hist[\"loss\"])\n",
    "plt.plot(hist[\"val_loss\"])\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Accuracy (training and validation)\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(hist[\"accuracy\"])\n",
    "plt.plot(hist[\"val_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92b91e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_path = f\"./hd_{model_name}\"\n",
    "tf.saved_model.save(model, saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073182bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
